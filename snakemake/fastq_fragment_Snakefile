"""
To see how Snakemake behaves with certain commands given the current config.json, 
try these examples:

Print jobs (and their shell commands) required to produce an aligned tumor DNA file:
snakemake -s fastq_fragment_Snakefile -np /data/smoking-sigs/5/workdir/tumor_aligned.sam --cores=24

Print jobs (and their shell commands) required to produce the MuTect2 output:
snakemake -s fastq_fragment_Snakefile -np /data/smoking-sigs/5/workdir/mutect.vcf --cores=24

To see a DAG of all the jobs:
snakemake --dag /data/smoking-sigs/5/workdir/mutect.vcf -s fastq_fragment_Snakefile | dot -Tsvg > ~/Desktop/dag.svg

Note that these commands need to be run from this directory. Also, this file assumes the 
existence of a config.json in the same directory with data of the form:

{
    "homedir": "path/to/homedir",
    "input": {
        "id": "some-id",
        "normal": [
            {
                "r1": "path/to/normal_L1_R1.fastq.gz",
                "r2": "path/to/normal_L1_R2.fastq.gz"
            },
            {
                "r1": "path/to/normal_L2_R1.fastq.gz",
                "r2": "path/to/normal_L2_R2.fastq.gz"
            }
        ],
        "tumor": [
            {
                "r1": "path/to/tumor_L1_R1.fastq.gz",
                "r2": "path/to/tumor_L1_R2.fastq.gz"
            },
            {
                "r1": "path/to/tumor_L2_R1.fastq.gz",
                "r2": "path/to/tumor_L2_R2.fastq.gz"
            }
        ]
    },
    "reference": {
        "genome": "path/to/genome.fasta",
        "dbsnp": "path/to/dbsnp.vcf"
    }
}

The files listed in this config have to exist.

"""

import os
from shutil import copy2

configfile: "pt002_config.json"

include:
    "gatk.rules"
include:
    "alignment.rules"

HOMEDIR = config["homedir"]
SAMPLE_ID = config["input"]["id"]

# TODO(julia): specify workdir in the config, don't infer it here
WORKDIR = os.path.join(HOMEDIR, SAMPLE_ID, "workdir")
PREFIX = os.path.join(WORKDIR, SAMPLE_ID)

CHR = list(range(1, 23)) + ['X', 'Y', 'MT']

# copy all fragments over to the workdir, create if it doesn't exist
if not os.path.exists(WORKDIR):
  os.makedirs(WORKDIR)

FRAGMENT_IDS = {
  "normal": set(),
  "tumor": set()
}

# naming convention for files in workdir: normal_L1_R1.fastq.gz
# Assume that all inputs are fastq.gz files.
for input_type in ["normal", "tumor"]:
  for fragment in config["input"][input_type]:
    for read in [1, 2]:
      assert fragment["r%d" % read].endswith("fastq.gz")
      FRAGMENT_IDS[input_type].add(fragment["fragment_id"])
      source = fragment["r%d" % read]
      # if either the .fastq.gz or .fastq files already exist, don't copy anew
      dest = os.path.join(WORKDIR,
        "%s_%s_R%d.fastq.gz" % (input_type, fragment["fragment_id"], read))
      unzipped_dest = os.path.join(WORKDIR,
        "%s_%s_R%d.fastq" % (input_type, fragment["fragment_id"], read))
      if not (os.path.exists(dest) or os.path.exists(unzipped_dest)):
        print('Copying %s to %s' % (source, dest))
        copy2(source, dest)

rule unzip_fastq:
  input:
    "{prefix}.fastq.gz"
  output:
    "{prefix}.fastq"
  shell:
    "gunzip {input}"

# merge a bunch of BAMs into one thing
# TODO(julia): only run a merge if necessary, otherwise if only one input, just copy over the file
rule merge_normal_aligned_fragments:
  input:
    expand("{{prefix}}_{fragment_id}_aligned_coordinate_sorted.bam",
      fragment_id=FRAGMENT_IDS["normal"])
  output:
    "{prefix}_merged_aligned_coordinate_sorted.bam"
  wildcard_constraints:
    prefix=".*normal.*"
  run:
    if len(input) > 1:
      shell("samtools merge {output} {input}")
    else:
      shell("cp {input} {output}")

# TODO(julia): only run a merge if necessary, otherwise if only one input, just copy over the file
rule merge_tumor_aligned_fragments:
  input:
    expand("{{prefix}}_{fragment_id}_aligned_coordinate_sorted.bam",
      fragment_id=FRAGMENT_IDS["tumor"])
  output:
    "{prefix}_merged_aligned_coordinate_sorted.bam"
  wildcard_constraints:
    prefix=".*tumor.*"
  run:
    if len(input) > 1:
      shell("samtools merge {output} {input}")
    else:
      shell("cp {input} {output}")

rule mutect2:
  input:
    normal = "{prefix}/normal_aligned_coordinate_sorted_dups_indelreal_bqsr.bam",
    tumor = "{prefix}/tumor_aligned_coordinate_sorted_dups_indelreal_bqsr.bam"
  output:
    "{prefix}/mutect2.vcf"
  params:
    reference = config["reference"]["genome"],
    dbsnp = config["reference"]["dbsnp"]
  benchmark:
    "{prefix}/mutect2_benchmark.txt"
  log:
    "{prefix}/mutect2.log"
  shell:
    "gatk -Xmx20g "
    "-T MuTect2 -I:normal {input.normal} -I:tumor {input.tumor} -R {params.reference} "
    "--dbsnp {params.dbsnp} -o {output} "
    "2> {log}"

# run a separate mutect task for each chromosome
rule mutect_per_chr:
  input:
    normal = "{prefix}/normal_aligned_coordinate_sorted_dups_indelreal_bqsr.bam",
    tumor = "{prefix}/tumor_aligned_coordinate_sorted_dups_indelreal_bqsr.bam"
  output:
    "{prefix}/mutect_{chr}.vcf"
  params:
    reference = config["reference"]["genome"],
    cosmic = config["reference"]["cosmic"],
    dbsnp = config["reference"]["dbsnp"]
  benchmark:
    "{prefix}/mutect_{chr}_benchmark.txt"
  log:
    "{prefix}/mutect_{chr}.log"
  shell:
    "java -Xmx2g -jar /biokepi/workdir/toolkit/mutect.NOVERSION/muTect-1.1.6-10b1ba92.jar "
    "--analysis_type MuTect "
    "--reference_sequence {params.reference} "
    "--cosmic {params.cosmic} "
    "--dbsnp {params.dbsnp} "
    "--intervals {wildcards.chr} "
    "--input_file:normal {input.normal} "
    "--input_file:tumor {input.tumor} "
    "--out {output}.out "
    "--vcf {output} "
    "--coverage_file {output}_coverage.wig"
 
rule mutect:
  input:
    expand("{{prefix}}/mutect_{chr}.vcf", chr=CHR)
  output:
    "{prefix}/mutect.vcf"
  shell:
    "vcf-concat {input} > {output}"
